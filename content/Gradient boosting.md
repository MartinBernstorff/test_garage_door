# Gradient boosting
<!-- #anki/deck/ML -->

Q. Describe the algorithm of gradient boosting
A. 1) Fit a regression, 2) Calculate residuals and use as labels, 3) Append new regression on residuals

Q. Describe the different purposes of boosting vs. bagging
A. Bagging reduces overfit, boosting reduces underfit

Q. How does gradient boosting reduce underfit?
A. It shapes the model by regressing on residuals

One example of this is [[XGBoost]].

<!-- #p1 Read up on Bagging in ML -->

<!-- {BearID:DF4A759F-6381-40F2-9AED-0C48E9430472-13135-000016886017E8D3} -->
