# §Multi-Armed Bandit Problem
A subtype of [[Explore or Exploit problem]]s.

## Backlinks
* [[Prioritise reading over meandering when the material is good]]
	* In that sense, we can use the [[§Multi-Armed Bandit Problem]] algorithm; keep "exploiting" (going to the reading list) for as long as that seems interesting, fun, and you don't regret it. As it starts to grow stale, switch more of your attention towards finding new material.

<!-- {BearID:12188457-0A9D-4CBA-8923-9F209A6ACCA0-8349-0000050B13AB11F1} -->
