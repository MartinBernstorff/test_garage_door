# The False Hope of Explainable AI ðŸ¤– - ExplainThisPaper
[The False Hope of Explainable AI ðŸ¤– - ExplainThisPaper](https://explainthispaper.com/the-false-hope-of-explainable-ai/)

What does this tell us about [[Explainable AI]] and [[Saliency methods]]?

In what sense are these methods useful right now? Should we trust them?

<!-- #Readable -->

<!-- {BearID:D04A9A30-2E6D-475B-96FF-D238C847FB64-37369-000004F21CEF9B56} -->
